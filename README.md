ğŸ“Š Challenge Telecom X: AnÃ¡lisis de EvasiÃ³n de Clientes â€“ Parte 2

ğŸ¯ Objetivo del Proyecto
Este proyecto busca construir el futuro de la retenciÃ³n de clientes en Telecom X mediante el uso de anÃ¡lisis estadÃ­sticos y modelos de Machine Learning. A travÃ©s de tÃ©cnicas avanzadas de clasificaciÃ³n y evaluaciÃ³n, se pretende responder preguntas clave como:

Â¿QuiÃ©nes son los clientes con mayor riesgo de evasiÃ³n?

Â¿QuÃ© variables influyen mÃ¡s en ese comportamiento?

Â¿QuÃ© perfil de cliente requiere mayor atenciÃ³n estratÃ©gica?

El conocimiento generado permitirÃ¡ implementar acciones de retenciÃ³n mÃ¡s efectivas y diseÃ±ar estrategias personalizadas, alineadas con los objetivos comerciales de la compaÃ±Ã­a. El enfoque se centra en maximizar el recall en la clase minoritaria (clientes que abandonan), sin comprometer excesivamente la precisiÃ³n, y reduciendo el impacto de falsos positivos en decisiones operativas.

ğŸ› ï¸ TecnologÃ­as y TÃ©cnicas Utilizadas
Lenguaje: Python

LibrerÃ­as: pandas, numpy, scikit-learn, imbalanced-learn, matplotlib, seaborn

TÃ©cnicas: SMOTE, GridSearchCV, permutation importance, VIF

MÃ©tricas clave: matriz de confusiÃ³n, recall, precisiÃ³n, F1-score, classification report

ğŸ” Pipeline de Modelado
Carga y limpieza de datos

AnÃ¡lisis exploratorio y visualizaciÃ³n

Balanceo de clases con SMOTE

Entrenamiento de modelos base:

Random Forest

RegresiÃ³n LogÃ­stica

KNN

Ãrbol de DecisiÃ³n

Ajuste de hiperparÃ¡metros con GridSearchCV

EvaluaciÃ³n con mÃ©tricas orientadas a negocio

InterpretaciÃ³n de variables con permutation importance y VIF

AutomatizaciÃ³n del flujo para reproducibilidad

ğŸ“ˆ Resultados y ComparaciÃ³n de Modelos

Modelo  ---   	Recall (Clase 1)---	 PrecisiÃ³n (Clase 1)---	 F1-score---	      Comentario
Random Forest	          0.82               	0.65	             0.73	          Buen balance entre recall y precisiÃ³n
RegresiÃ³n LogÃ­stica	    0.76	              0.70	             0.73	          MÃ¡s interpretable, pero menor recall
KNN	                    0.68	              0.60	             0.64	          Sensible al escalado y ruido
Ãrbol de DecisiÃ³n	      0.74	              0.62	             0.67	          FÃ¡cil de visualizar, pero menos robusto

Nota: los valores son ilustrativos. Se deben actualizar con los resultados reales del proyecto.

ğŸ“Œ Conclusiones
El modelo con mejor desempeÃ±o en recall fue Random Forest, ideal para minimizar falsos negativos.

La interpretaciÃ³n de variables clave permite orientar campaÃ±as de retenciÃ³n mÃ¡s efectivas.

Se automatizÃ³ el pipeline para facilitar futuras iteraciones y pruebas con nuevos datos.

ğŸ“ PrÃ³ximos Pasos
ValidaciÃ³n cruzada con datos recientes

Pruebas en entorno productivo

IntegraciÃ³n con sistemas de toma de decisiones comerciales
